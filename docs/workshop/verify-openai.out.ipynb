{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup and verify Openai\n",
        "\n",
        "[Andrew Ellis](https://github.com/awellis)\n",
        "[![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==)](https://orcid.org/0000-0002-2788-936X)\n",
        "([Virtual Academy, Bern University of Applied\n",
        "Sciences](https://virtuelleakademie.ch))  \n",
        "13 Nov, 2024\n",
        "\n",
        "Your OpenAI API key is stored in your `.env` file. You can access it\n",
        "with the following code:"
      ],
      "id": "03f5971b-209d-4e02-b937-bfd0a05e49ba"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "from IPython.display import display, Markdown"
      ],
      "id": "cell-2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Create OpenAI client with API key\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
      ],
      "id": "cell-3"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_ai_response(message, temperature=1.0, width=80):\n",
        "    \"\"\"\n",
        "    Get a response from OpenAI's API and display it wrapped in the notebook.\n",
        "    \n",
        "    Args:\n",
        "        message (str): The user's input message\n",
        "        temperature (float): Controls randomness (0.0 to 2.0, default 1.0)\n",
        "        width (int): Maximum line width for text wrapping\n",
        "        \n",
        "    Returns:\n",
        "        str: The AI's response text\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[{\"role\": \"user\", \"content\": message}],\n",
        "            temperature=temperature,\n",
        "            max_tokens=2048,\n",
        "            response_format={\"type\": \"text\"}\n",
        "        )\n",
        "        \n",
        "        # Get the response text\n",
        "        text = response.choices[0].message.content\n",
        "        \n",
        "        # Option 1: Display as wrapped Markdown\n",
        "        display(Markdown(f\"```\\n{text}\\n```\"))\n",
        "        \n",
        "        # return text\n",
        "        \n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\""
      ],
      "id": "cell-4"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "get_ai_response(\"Hello, how are you?\")"
      ],
      "id": "cell-get-ai-response"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "import textwrap\n",
        "\n",
        "def get_ai_response_2(message, temperature=1.0, width=80):\n",
        "    \"\"\"\n",
        "    Get a response from OpenAI's API and display it wrapped in the notebook.\n",
        "    \n",
        "    Args:\n",
        "        message (str): The user's input message\n",
        "        temperature (float): Controls randomness (0.0 to 2.0, default 1.0)\n",
        "        width (int): Maximum line width for text wrapping\n",
        "        \n",
        "    Returns:\n",
        "        str: The AI's response text\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[{\"role\": \"user\", \"content\": message}],\n",
        "            temperature=temperature,\n",
        "            max_tokens=2048,\n",
        "            response_format={\"type\": \"text\"}\n",
        "        )\n",
        "        # Get the response text\n",
        "        text = response.choices[0].message.content\n",
        "        \n",
        "        # Option 2: Wrap text using textwrap\n",
        "        wrapped_text = textwrap.fill(text, width=width)\n",
        "        print(wrapped_text)\n",
        "        \n",
        "        # return text\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\""
      ],
      "id": "cell-6"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As an artificial intelligence, I don't have feelings, but I'm functioning as\n",
            "expected. Thank you! How can I assist you today?"
          ]
        }
      ],
      "source": [
        "get_ai_response_2(\"Hello, how are you?\")\n"
      ],
      "id": "get-ai-response-2"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "venv",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  }
}