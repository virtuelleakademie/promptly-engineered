{
  "hash": "9a293571a9a692132ec4d35a6fc954f1",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Project: Anki flashcards\"\njupyter: python3\n---\n\n\n\n\n## Setup\n\nTo get started, you can clone the repository containing the project files:\n\n```bash\ngit clone https://github.com/awellis/anki-flashcard-generator\n```\n\nor simply download the zip file from my [Github repository](https://github.com/awellis/anki-flashcard-generator).\n\n\n![](../../assets/images/github-anki.png){width=80%}\n\n\nOnce you cloned the repository, or downloaded and unzipped the zip file, you will find the following files:\n\n```bash\nassets/baroque-essay.md\nassets/classical-essay.md\nassets/romantic-essay.md\nassets/modern-essay.md\n```\nThese files contain the teaching material for the four musical eras, based on which we will generate the flashcards. \n\n```bash\ngenerate-anki-flashcards.py\n```\nThis file contains a Python script to get you started.\n\n## Task 1: Create an LLM client\n\nFirst, you will to set up an LLM client. We will use the `openai` Python package to connect to an OpenAI model.\n\n(@) import the `openai` package\n(@) import the `dotenv` package to load the API key from the `.env` file\n(@) set up the client with your OpenAI API key\n\n\n## Task 2: Read the teaching material\n(@) read one of the essay files, and print the contents\n\n\n\n## Task 3: Extract pairs of questions and answers\nNow you can think about how you can extract pairs of questions and answers from the teaching material. You will need to write a suitable prompt, consisting of a system message and a user message, to guide the LLM in extracting the questions and answers.\n\n(@) write a prompt to extract pairs of questions and answers from the teaching material\n\n## Task 4: Call the LLM\n\n(@) call the LLM with the prompt, and print the result\n  + try out both GPT-4o and GPT-4o Mini\n  + try out different parameters settings for the LLM call (e.g. `temperature`, `top_p`)\n\n## Task 5: Use structured outputs\n\n(@) use structured outputs to control the format of the LLM's response: Define a `pydantic` model to describe the format of the LLM's response\n(@) call the LLM with the structured output format\n\n## Task 6: Make your code reusable\n\n(@) write a function to call the LLM with the prompt and an arbitrary text\n(@) call the function with the prompt, and print the result\n\n## Task 7: Write the results to a CSV file\n\n(@) write the results to a CSV file. Code is provided for you.\n\n## Task 8: Extract questions and answers from all the teaching material\n\n(@) write a loop to load all essays, extract questions and answers from all the teaching material, and write the results to a CSV file\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}